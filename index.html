<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions">
    <meta name="keywords" content="VLM, Humor Understanding, Juxtaposition">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

</head>
<body>

<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><br>Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions
            </h1>
                <div class="is-size-4 publication-authors">
                <!-- Paper authors -->
                  <span class="author-block">
                  <a href="https://derekhu.com/" target="_blank"><br>Zhe Hu*<sup>1</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://Tuo-Liang.github.io" target="_blank">Tuo Liang*<sup>2</sup></a>,</span>
                  <span class="author-block">
                  <a href="" target="_blank">Jing Li<sup>1</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://yiren-lu.com/" target="_blank">Yiren Lu<sup>2</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://www.linkedin.com/in/%E4%BA%91%E6%9D%A5-%E5%91%A8-932a022aa/?locale=en_US" target="_blank">Yunlai Zhou<sup>2</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://www.linkedin.com/in/yiran-qiao-10298b238/" target="_blank">Yiran Qiao<sup>2</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://jma712.github.io/" target="_blank">Jing Ma<sup>2</sup></a>,</span>
                  <span class="author-block">
                  <a href="https://yin-yu.github.io/" target="_blank">Yu Yin<sup>2</sup></a>
                  </span>
                </div>

                <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University   <sup>2</sup>Case Western Reserve University<br>
                    </span>
                </div>
                <div class="is-size-4 publication-authors"> <font color = 'red';><b>NeurIPS 2024 (Oral)</b></font><br> </div>
                <div class="is-size-4 publication-authors"> <span class="eql-cntrb"><small><sup>*</sup>Indicates Equal Contribution</small><br> </div>
                

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://neurips.cc/virtual/2024/oral/97967" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/html/2405.19088v1" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Tuo-Liang/YESBUT" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Dataset & Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/intro_example.jpg" alt="MY ALT TEXT"/>
      </div>
      <div class="content has-text-justified">
        <p>
            We introduce the <span class="is-size-5 dnerf"><b>YesBut</b> </span> dataset to examine VLMs' capability in understanding humor, with a specific emphasis on humor derived from contrasting narratives (juxtaposition). (Comic by Anton Gudim)
        </p>
        
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Abstract -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Abstract</h2>
      </div>
      <div class="content has-text-justified">
        <p>
          Recent advancements in large multimodal language models have demonstrated remarkable proficiency across a wide range of tasks. 
          Yet, these models still struggle with understanding the nuances of human humor through juxtaposition, particularly when it involves nonlinear narratives that underpin many jokes and humor cues.  This paper investigates this challenge by focusing on comics with contradictory narratives, where each comic consists of two panels that create a humorous contradiction. 
          We introduce the <span class="dnerf"><b>YesBut</b> </span> benchmark, which comprises tasks of varying difficulty aimed at assessing AI's capabilities in recognizing and interpreting these comics, ranging from literal content comprehension to deep narrative reasoning. 
          Through extensive experimentation and analysis of recent commercial or open-sourced large (vision) language models, we assess their capability to comprehend the complex interplay of the narrative humor inherent in these comics. Our results show that even state-of-the-art models still lag behind human performance on this task. Our findings offer insights into the current limitations and potential improvements for AI in understanding human creative expressions.
        </p>
    </div>
  </div>
</section>
<!-- End Abstract -->

<!-- Dataset overview -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3"><span class="dnerf">YesBut</span> Dataset Overview</h2>
      </div>
      <div class="content has-text-justified">
        <p>
          Our benchmark consists of <span class="dnerf">YesBut</span> comics featuring contradictory narratives. Specifically, each sample includes:<br>
            (1) a two-panel comic that forms a narrative with inherent contradictions;
            <br>
            (2) a literal description of the comic narratives;
            <br>
            (3) an explanation that illustrates the contradiction within the narrative;
            <br>
            (4) the deep philosophy or underlying message the comic aims to convey;
            <br>
            (5) a title of the comic.
            <br>
            Based on these components, we construct various tasks for comic understanding.
        </p>

    </div>
  </div>
</section>
<!-- End pipeline overview -->

<!-- Pipeline overview -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Data Construction Pipeline</h2>
      </div>
      <div class="item">
        <img src="static/images/annotation_pipeline.jpg" alt="MY ALT TEXT"/>
      </div>
      <div class="content has-text-justified">
        <p>
          <br>For each comic, we annotate the corresponding literal description, contradiction explanation, underlying philosophy and comic title. The annotation process consists of two key stages: a <b>human-AI collaborative annotation stage</b> (steps 1 & 2) followed by a <b>quality check and cross-verification stage</b> (step 3). Gold-standard annotations are primarily obtained through human annotators. ('Pos' and 'Neg' in figure represent the positive and negative options, respectively.)
        </p>
    </div>
  </div>
</section>
<!-- End Pipeline overview -->

<!-- Tasks -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <h2 class="title is-3">Evaluating Large Models' Understanding of Humor in Juxtaposition: Task Designs from Our Paper</h2>
        </div>
        <div class="content has-text-justified">
          <p>
            We aim to evaluate the capabilities of recent large (visual) language models in understanding humor through contradictions. This is challenging because it requires both <b>social reasoning</b> about human events and <b>nonlinear logical reasoning</b> about the narratives, going beyond the literal understanding of the comic. We design a series of tasks that require different levels of narrative understanding and reasoning abilities to evaluate the models’ performance in reading comics.
          </p>
        </div>
        <div class="item">
          <img src="static/images/tasks.jpg" alt="MY ALT TEXT"/>
        </div>
    </div>
  </div>
</section>
<!-- End Tasks -->

<!-- Results: Error Analysis and Future Directions -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container has-text-centered">
            <h2 class="title">When VLM fails and future directions</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <!-- <ul>
                    <li>
                        <h2 class="subtitle is-4">Evaluating Large Models' Understanding of Humor in Juxtaposition: Task Designs from Our Paper</h2>
                        
                    </li>
                    <li>In-depth Reasoning of the Relationship</li>
                    <li>Hallucination and Incorrect Association</li>
                </ul> -->
                 <!-- Carousel Inner -->


            </div>
        </div>
    </div>
</section>
<br/>
<!-- End Tasks -->


<!-- pipeline overview -->
<!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <h2 class="title has-text-centered">Mask Consistency</h2>
          <div class="row d-flex justify-content-around">
            <div class="content has-text-justified">
              <p class="content has-text-justified">Our multi-view segmentation approach can not only maintain mask consistency across different views, but can also take regions without semantic meanings into consideration (i.e. the shadow on the left side of the book).
              </p>
            </div>
            <div class="col-5 p-1">
              <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/ori_book_spiral_050000_rgb.mp4"
                        type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">Original Scene</h2>
            </div>
            <div class="col-5 p-1">
              <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/book_mask.mp4"
                        type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">Masks</h2>
            </div>
          </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End pipeline overview -->


<!-- pipeline overview -->
<!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">Citation</h2>
        <p>If you find our work helpful, please consider cite us:</p>
        <pre><code>@misc{lu2024viewconsistentobjectremovalradiance,
          title={View-consistent Object Removal in Radiance Fields}, 
          author={Yiren Lu and Jing Ma and Yu Yin},
          year={2024},
          eprint={2408.02100},
          archivePrefix={arXiv},
          primaryClass={cs.CV},
          url={https://arxiv.org/abs/2408.02100}, 
    }
</code></pre>
    </div>
</section> -->
<!-- End pipeline overview -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>Website template borrowed from <a href="https://spinnerf3d.github.io/">SPIn-NeRF</a> and <a href="https://github.com/ornerf/ornerf.github.io">OR-NeRF</a>.</p>
                    <p>
                        This website is licensed under a <a rel="license"
                                                            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <!-- <p>
                        This means you are free to borrow the <a
                            href="https://github.com/ornerf/ornerf.github.io">source code</a> of this website,
                        we just ask that you link back to this page in the footer.
                        Please remember to remove the analytics code included in the header of the website which
                        you do not want on your website.
                    </p> -->
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
